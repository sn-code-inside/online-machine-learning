{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Chapter 5\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supplementary material of the books \"Online Machine Learning - Eine praxisorientiere Einf√ºhrung\",  \n",
    "https://link.springer.com/book/9783658425043 and \"Online Machine Learning - A Practical Guide with Examples in Python\" https://link.springer.com/book/9789819970063\n",
    "The contents are open source and published under the \"BSD 3-Clause License\".\n",
    "This software is provided \"as is\" without warranty of any kind, either express or implied, including but not limited to implied warranties of merchantability and fitness for a particular purpose. The author or authors assume no liability for any damages or liability, whether in contract, tort, or otherwise, arising out of or in connection with the software or the use or other dealings with the software."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Evaluation und Performance Measurement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determination of the training and test data set in the 'spotRiver' package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import linear_model, datasets, preprocessing\n",
    "from spotRiver.evaluation.eval_bml import eval_oml_horizon\n",
    "from spotRiver.utils.data_conversion import convert_to_df\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "metric = mean_absolute_error\n",
    "model = (preprocessing.StandardScaler() |\n",
    "        linear_model.LinearRegression())\n",
    "dataset = datasets.TrumpApproval()\n",
    "target_column = \"Approve\"\n",
    "df = convert_to_df(dataset, target_column)\n",
    "train = df[:500]\n",
    "test = df[500:]\n",
    "horizon = 10\n",
    "df_eval, df_preds = eval_oml_horizon(\n",
    "    model, train, test, target_column,\n",
    "    horizon, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gnerate directory \"figures\" if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_metrics\n",
    "df_labels = [\"OML Linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval, df_labels, metric=metric, filename=\"./figures/ch05_fig_bml_oml_horizon_metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.evaluation.eval_bml import plot_bml_oml_horizon_predictions\n",
    "df_labels = [\"OML Linear\"]\n",
    "plot_bml_oml_horizon_predictions(df_preds, df_labels, target_column=target_column, filename=\"./figures/ch05_fig_bml_oml_horizon_predictions.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for OML (River)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive, plot_oml_iter_progressive\n",
    "from river import metrics as river_metrics\n",
    "from river import tree as river_tree\n",
    "from river import preprocessing as river_preprocessing\n",
    "dataset = datasets.TrumpApproval()\n",
    "model =  (river_preprocessing.StandardScaler() | river_tree.HoeffdingAdaptiveTreeRegressor(seed=1))\n",
    "\n",
    "res_num = eval_oml_iter_progressive(\n",
    "    dataset = list(dataset),\n",
    "    step = 1,\n",
    "    metric = river_metrics.MAE(),\n",
    "    models =\n",
    "    {\n",
    "        \"HATR\": model,\n",
    "    }\n",
    ")\n",
    "plot_oml_iter_progressive(res_num, filename=\"./figures/ch05-eval_oml_iter_progressive.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEA Drift\n",
    "\n",
    "As shown in [https://riverml.xyz/0.15.0/api/tree/HoeffdingAdaptiveTreeClassifier/](https://riverml.xyz/0.15.0/api/tree/HoeffdingAdaptiveTreeClassifier/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive, plot_oml_iter_progressive\n",
    "from spotRiver.evaluation.eval_bml import eval_bml_horizon, eval_bml_landmark, eval_bml_window, eval_oml_horizon, plot_bml_oml_horizon_predictions, plot_bml_oml_horizon_metrics\n",
    "from spotRiver.utils.data_conversion import convert_to_df\n",
    "from river import metrics as river_metrics, compose, feature_extraction, linear_model, preprocessing, stats\n",
    "from river import stream as river_stream\n",
    "from river import preprocessing as river_preprocessing\n",
    "from river.datasets import synth\n",
    "from river.tree import HoeffdingAdaptiveTreeClassifier, HoeffdingTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import preprocessing as preprocessing_sklearn\n",
    "from sklearn import tree as sklearn_tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: metric = accuracy_score\n",
    "metric = f1_score\n",
    "horizon = 7*24\n",
    "k = 10 \n",
    "n_total = int(k*100_000)\n",
    "position = int(k*25_000)\n",
    "width = int(n_total/250)\n",
    "n_train = 1_000\n",
    "a = n_train + position - 50\n",
    "b = a + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_1 = synth.ConceptDriftStream(\n",
    "        stream=synth.SEA(seed=42, variant=0),\n",
    "        drift_stream=synth.SEA(seed=42, variant=1),\n",
    "                               seed=1, position=position, width=width)\n",
    "gen_2 = synth.ConceptDriftStream(\n",
    "        stream=synth.SEA(seed=42, variant=2),\n",
    "        drift_stream=synth.SEA(seed=42, variant=3),\n",
    "                               seed=1, position=position, width=width)\n",
    "dataset = synth.ConceptDriftStream(stream=gen_1, drift_stream=gen_2, seed=1, position=2*position, width=width)\n",
    "data_dict = {key: [] for key in list(dataset.take(1))[0][0].keys()}\n",
    "data_dict[\"y\"] = []\n",
    "for x, y in dataset.take(n_total):\n",
    "    for key, value in x.items():\n",
    "        data_dict[key].append(value)\n",
    "    data_dict[\"y\"].append(y)\n",
    "df = pd.DataFrame(data_dict)\n",
    "# Add column names x1 until x10 to the first 10 columns of the dataframe and the column name y to the last column\n",
    "df.columns = [f\"x{i}\" for i in range(1, 4)] + [\"y\"]\n",
    "df = df.apply(lambda x: x.astype(int) if x.dtype == bool else x)\n",
    "train = df[:n_train]\n",
    "test = df[n_train:]\n",
    "target_column = \"y\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the y values of the samples in the df dataframe using a sliding window of 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the y values of the samples in the df dataframe using a sliding window of 1000 samples\n",
    "fig = plt.figure(figsize=(7,3), tight_layout=True)\n",
    "df[\"y\"].rolling(2500).mean().plot()\n",
    "plt.axvline(position, color=\"red\")\n",
    "plt.axvline(2*position, color=\"red\")\n",
    "plt.axvline(3*position, color=\"red\")\n",
    "fig.savefig(\"./figures/ch05_sea_drift.pdf\", format='pdf', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation, Performance Measurement\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Metrics Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of the \"Rolling\" Metric\n",
    "\n",
    "* The method `Rolling` from the package `river` calculates a metric for the data of a sliding window $W$, where the parameter `window_size` specifies the window size $w$.\n",
    "* In the example, the accuracy is calculated with a window size $w=3$:\n",
    "* The first value is 0%, since `{True}` and `{False}` occur.\n",
    "* The second value is 50%, since `{True, False}` are compared with `{False, False}`.\n",
    "* The third value is 66%, since `{True, False, True}` are compared with `{False, False, True}`.\n",
    "* The fourth value is 100%, since `{False, True, True}` are compared with `{False, True, True}`. The error in the first sample does not matter anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics, utils\n",
    "\n",
    "y_true = [True, False, True, True] \n",
    "y_pred = [False, False, True, True]\n",
    "\n",
    "metric = utils.Rolling(metrics.Accuracy(), window_size=3)\n",
    "\n",
    "for yt, yp in zip(y_true, y_pred): \n",
    "    print(metric.update(yt, yp)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Validation\n",
    "\n",
    "## First Example: Progressive Validation (without delay)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using  the California Housing dataset.\n",
    "\n",
    "* First we load the California Housing dataset.\n",
    "  \n",
    "* Then store the independent variables as `X` and the target variable as `y`.\n",
    "* The data can then be incrementally retrieved as `dataset` via an iterator that uses the `river` method `stream.iter_pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "california_housing = fetch_california_housing()\n",
    "features = california_housing.feature_names\n",
    "X = pd.DataFrame(california_housing.data, columns=features)\n",
    "y = pd.Series(california_housing.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a datetime date column to the dataframe X and the feature \"moment\" to the list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"date\"] = pd.date_range(start=\"2020-01-01\", periods=len(X), freq=\"D\")\n",
    "# features.append(\"moment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream\n",
    "dataset = stream.iter_pandas(X, y)\n",
    "for x, y in dataset:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "* A linear regression model is selected as the model.\n",
    "* A pipeline is set up in which the characteristics are first selected using 'Select' and then scaled before they are passed on to the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose, preprocessing, linear_model, optim\n",
    "model = compose.Select(*features)\n",
    "model |= preprocessing.StandardScaler()\n",
    "model |= linear_model.LinearRegression(optimizer=optim.SGD(0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the MAE (Mean Absolute Errors) using progressive validation (Test-Then-Train).\n",
    "\n",
    "* Progressive validation is the canonical method to evaluate the performance of a model. \n",
    "* It can be used to estimate how a model would have performed in a production scenario.\n",
    "* The data set is transformed into a stream of questions and answers. \n",
    "  * At each step, the model is either asked to predict an observation or is either updated. \n",
    "  * The target is revealed to the model only after a certain time, which is determined by the delay parameter (`delay`). \n",
    "* By default, there is no delay, which means that the samples are processed sequentially. If there is no delay, this function performs a progressive validation (test-then-train). \n",
    "* When there is a delay, we refer to this as delayed progressive validation.\n",
    "* In the first example, the MAE is displayed after `print_every=5000` steps, but is updated after each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics, evaluate\n",
    "metric = metrics.MAE()\n",
    "evaluate.progressive_val_score(dataset, model, metric, print_every=5_000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Example: Progressive Validation with Delay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the second example `delay=dt.timedelta(days=1)` is set and thus a delay is built in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "X = pd.DataFrame(california_housing.data, columns=features)\n",
    "y = pd.Series(california_housing.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add a datetime date column to the dataframe X and the feature \"moment\" to the list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X[\"moment\"] = pd.date_range(start=\"2020-01-01\", periods=len(X), freq=\"D\")\n",
    "dataset = stream.iter_pandas(X, y)\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=dataset,\n",
    "    model=model.clone(),\n",
    "    metric=metric,\n",
    "    moment=\"moment\",\n",
    "    delay=dt.timedelta(days=1),\n",
    "    print_every=5_000\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increase the delay to two weeks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(california_housing.data, columns=features)\n",
    "y = pd.Series(california_housing.target)\n",
    "\n",
    "# add a datetime date column to the dataframe X and the feature \"moment\" to the list of features\n",
    "X[\"moment\"] = pd.date_range(start=\"2020-01-01\", periods=len(X), freq=\"D\")\n",
    "\n",
    "dataset = stream.iter_pandas(X, y)\n",
    "\n",
    "evaluate.progressive_val_score(\n",
    "    dataset=dataset,\n",
    "    model=model.clone(),\n",
    "    metric=metric,\n",
    "    moment='moment',\n",
    "    delay=dt.timedelta(days=14),\n",
    "    print_every=5_000\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Simulator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: The synthetic SEA data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Implementation of the abrupt drift data stream described in [@stre01a]. \n",
    "* Each observation consists of three features. \n",
    "  * Only the first two features are relevant. \n",
    "* The target is binary and positive if the sum of the features exceeds a certain threshold. \n",
    "* There are four thresholds to choose from. \n",
    "* Concept drift can be introduced at any time during the stream by switching the threshold.\n",
    "\n",
    "* In detail, the SEA dataset were generated as follows: \n",
    "  * First, $n=60,000$ random points were generated in a three-dimensional feature space. \n",
    "  * The features have values between 0 to 10, with only the first two features ($f_1$ and $f_2$) being relevant. \n",
    "  * The $n$ points were then divided into four blocks of $15,000$ points each. \n",
    "  * In each block, the class membership of a point is determined using a threshold $\\tau_i$, where $i$ indicates the block in question.\n",
    "  * Thresholds $\\tau_1= 8$, $\\tau_2=9$, $\\tau_3=7$, and $\\tau_4 = 9.5$ were chosen. \n",
    "  * In addition, the data were noisy (\"We inserted about 10% class noise into each block of data.\") by swapping 10% of the class memberships. \n",
    "  * Finally, a test set ($n_t = 10,000$) was determined, each composed of $2,500$ data points taken from each block.\n",
    "* The python package `river` provides the function `SEA` to generate the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data iterator\n",
    "\n",
    "* First we create the iterator `dataset`, with which we create $n$ records and store them in the two lists\n",
    "\n",
    "* `xl` and\n",
    "* `yl`\n",
    "\n",
    "as `float` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.datasets import synth\n",
    "n = 12500 # size test data of each class. There are 4 classes.\n",
    "k = 2500 # size test data set of each class.\n",
    "test = dict()\n",
    "train = dict()\n",
    "\n",
    "for i in range(4): \n",
    "    xtrain = []\n",
    "    ytrain = []\n",
    "    xtest = []\n",
    "    ytest = []\n",
    "\n",
    "    dataset = synth.SEA(variant=i, seed=2*i)\n",
    "    for x, y in dataset.take(n):\n",
    "        xtrain.append( [float(a) for a in list(x.values()) ])\n",
    "        ytrain.append(y)\n",
    "    train[i] = [xtrain, ytrain]\n",
    "\n",
    "    dataset = synth.SEA(variant=i, seed=2*i+1)\n",
    "    for x, y in dataset.take(k):\n",
    "        xtest.append( [float(a) for a in list(x.values()) ])\n",
    "        ytest.append(y)\n",
    "    test[i] = [xtest, ytest]\n",
    "    \n",
    "#print(test[0][0])\n",
    "#print(test[0][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The complete SEA data set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The four partial data sets are now combined into one overall data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train[0][0] + train[1][0] + train[2][0] + train[3][0]\n",
    "Ytrain = train[0][1] + train[1][1] + train[2][1] + train[3][1]\n",
    "\n",
    "Xtest = test[0][0] + test[1][0] + test[2][0] + test[3][0]\n",
    "Ytest = test[0][1] + test[1][1] + test[2][1] + test[3][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model (decision tree)\n",
    "\n",
    "* A decision tree is now fitted on the complete data set. \n",
    "* The first levels of the tree are visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(Xtrain, Ytrain)\n",
    "tree.plot_tree(clf, max_depth=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graphviz\n",
    "\n",
    "* If the library `graphviz` is available (on operating system level and then as Python interface), appealing graphics can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=\"sae_tree.dot\", max_depth=2, filled=True)\n",
    "! dot -Tpng sae_tree.dot -o sae_tree.png "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='sae_tree.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the SEA test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(Ytest,\n",
    "                                            Ypred)\n",
    "\n",
    "matrix_df = pd.DataFrame(confusion_matrix)\n",
    "ax = plt.axes()\n",
    "sns.set(font_scale=1.3)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "ax.set_title('Confusion Matrix - Decision Tree')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spotCondaEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
