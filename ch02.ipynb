{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Chapter 2\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supplementary material of the books \"Online Machine Learning - Eine praxisorientiere Einführung\",  \n",
    "https://link.springer.com/book/9783658425043 and \"Online Machine Learning - A Practical Guide with Examples in Python\" https://link.springer.com/book/9789819970063\n",
    "The contents are open source and published under the \"BSD 3-Clause License\".\n",
    "This software is provided \"as is\" without warranty of any kind, either express or implied, including but not limited to implied warranties of merchantability and fitness for a particular purpose. The author or authors assume no liability for any damages or liability, whether in contract, tort, or otherwise, arising out of or in connection with the software or the use or other dealings with the software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Supervised Learning: Classification and Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear online regression with River\n",
    "\n",
    "* Linear online regression can be performed in `river` with the `LinearRegression` class \n",
    "from the `linear_model` module. \n",
    "* In the following example, the MAE (mean absolute error) error is measured during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, we create a dataset for classification using the `sklearn.datasets` class `make_classification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a classification dataset with sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=2, n_redundant=2, random_state=42)\n",
    "\n",
    "## Convert X to a pandas dataframe\n",
    "import pandas as pd\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswahl der Metrik und der Datenvorverarbeitung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Mean Absolute Error (MAE) is selected as the metric.\n",
    "* In addition, the scaling of the data is specified:\n",
    "  * By selecting the `StandardScalers` class, the data is scaled to have zero mean and one variance.\n",
    "  * Internally, a running mean and running variance are determined. This scaling differs slightly from the scaling of the data in the batch because the exact means and variances are not known in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import metrics\n",
    "from river import preprocessing\n",
    "\n",
    "metric = metrics.MAE()\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the model\n",
    "\n",
    "* In the next step the model (here the `LinearRegression`) is selected.\n",
    "* For the sequential online optimization of the model coefficients, the stochastic gradient descent (`SGD`) is selected.\n",
    "  * The learning rate for `SGD` is set to 0.01. \n",
    "  * The setting of a suitable learning rate is crucial for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import optim\n",
    "from river import linear_model\n",
    "\n",
    "optimizer = optim.SGD(lr=0.01)\n",
    "lin_reg = linear_model.LinearRegression(optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-then-train \n",
    "\n",
    "* Now the single samples of the dataset are used for testing and training. \n",
    "  * For each sample, the metric is updated.\n",
    "* Finally, the metric that was incrementally calculated on the data from the entire process is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "metric_list = []\n",
    "\n",
    "for xi, yi in stream.iter_pandas(X, y):\n",
    "\n",
    "    # Scale the features\n",
    "    xi_scaled = scaler.learn_one(xi).transform_one(xi)\n",
    "\n",
    "    # Test the current model on the new \"unobserved\" sample\n",
    "    yi_pred = lin_reg.predict_one(xi_scaled)\n",
    "    # Train the model with the new sample\n",
    "    lin_reg.learn_one(xi_scaled, yi)\n",
    "\n",
    "    # Store the truth and the prediction\n",
    "    y_true.append(yi)\n",
    "    y_pred.append(yi_pred)\n",
    "    metric = metric.update(yi, yi_pred)\n",
    "    # Store the metric after each sample in a list\n",
    "    metric_list.append(metric.get( ))\n",
    "\n",
    "print(metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the values of the metric_list versus the sample number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the values of the metric_list verus the number of samples\n",
    "plt.plot(metric_list)\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Da der `SGD` nicht-deterministisch ist, führt jeder Aufruf zu einem (leicht) modifizierten Ergebnis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (ALMA) Classification for Synthetic Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data \n",
    "\n",
    "* Synthetic classification data is generated using the `make_classification` function from the `sklearn` package, see [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html).\n",
    "  * This function allows the creation of classification problems with $n$ classes.\n",
    "  * In our example, $n=2$ is chosen (this is the default).  \n",
    "* The data is then split into the training and test datasets using the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from river import linear_model\n",
    "\n",
    "X, y = make_classification(shuffle=True, n_samples=2000)\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.ALMAClassifier()\n",
    "\n",
    "# fit the model\n",
    "for x_i,y_i in zip(X_train,y_train):\n",
    "    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}\n",
    "    model.learn_one(x_json,y_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test set and compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for x_i in X_test:\n",
    "    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}\n",
    "    preds.append(model.predict_one(x_json))\n",
    "\n",
    "# compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the scikit-learn \"classification report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (ALMA) classification for a sklearn classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a classification dataset with sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=20, n_informative=2, n_redundant=2, random_state=42)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "## Convert X to a pandas dataframe\n",
    "import pandas as pd\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model is fitted on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.ALMAClassifier()\n",
    "for xi, yi in stream.iter_pandas(X_train,y_train):\n",
    "    xi_scaled = scaler.learn_one(xi).transform_one(xi)\n",
    "    model.learn_one(xi_scaled, yi) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Prediction on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for xi, _ in stream.iter_pandas(X_test):    \n",
    "    xi_scaled = scaler.learn_one(xi).transform_one(xi)\n",
    "    preds.append(model.predict_one(xi_scaled))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computation of the accuracy metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passiv-Aggressiv Classification for Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y=make_classification(shuffle=True,n_samples=2000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from river import linear_model\n",
    "\n",
    "model = linear_model.PAClassifier()\n",
    "\n",
    "for x_i,y_i in zip(X_train,y_train):\n",
    "    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}\n",
    "    model.learn_one(x_json,y_i)\n",
    "    \n",
    "\n",
    "preds = []\n",
    "for x_i in X_test:\n",
    "    x_json = {'val'+str(i): x for i,x in enumerate(x_i)}\n",
    "    preds.append(model.predict_one(x_json))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "from river import datasets\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from river.datasets import synth\n",
    "from river import tree\n",
    "\n",
    "from river.datasets import synth\n",
    "\n",
    "dataset = synth.SEA(variant=0, seed=42)\n",
    "#dataset = datasets.Phishing()\n",
    "data = dataset.take(10000)\n",
    "\n",
    "model = tree.HoeffdingTreeClassifier(grace_period=50)\n",
    "\n",
    "for x, y in data:\n",
    "    print(x, y)\n",
    "    x = {f'x_{key}': value for key, value in x.items()}\n",
    "    print(x,y)\n",
    "    model.learn_one(x, y)\n",
    "\n",
    "model\n",
    "\n",
    "model.summary\n",
    "\n",
    "model.draw()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spotCondaEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
