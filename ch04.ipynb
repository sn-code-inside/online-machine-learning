{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Chapter 4\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supplementary material of the books \"Online Machine Learning - Eine praxisorientiere EinfÃ¼hrung\",  \n",
    "https://link.springer.com/book/9783658425043 and \"Online Machine Learning - A Practical Guide with Examples in Python\" https://link.springer.com/book/9789819970063\n",
    "The contents are open source and published under the \"BSD 3-Clause License\".\n",
    "This software is provided \"as is\" without warranty of any kind, either express or implied, including but not limited to implied warranties of merchantability and fitness for a particular purpose. The author or authors assume no liability for any damages or liability, whether in contract, tort, or otherwise, arising out of or in connection with the software or the use or other dealings with the software."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Initial Selection and Subsequent Update of OML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset `ImageSegemnts` \n",
    "\n",
    "* This dataset contains 18 features describing image segments in seven classes: \n",
    "  * brickface (brick wall), \n",
    "  * sky (sky), \n",
    "  * foliage (foliage), \n",
    "  * cement (cement), \n",
    "  * window, \n",
    "  * path (path) and \n",
    "  * grass (grass).\n",
    "\n",
    "* Instances were randomly drawn from a database of seven outdoor images. \n",
    "* 18 attributes ($x$ values) are used.\n",
    "* The images were segmented by hand to create a classification for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageSegments()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Attributes and class of the first data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'region-centroid-col': 218,\n",
       "  'region-centroid-row': 178,\n",
       "  'short-line-density-5': 0.11111111,\n",
       "  'short-line-density-2': 0.0,\n",
       "  'vedge-mean': 0.8333326999999999,\n",
       "  'vegde-sd': 0.54772234,\n",
       "  'hedge-mean': 1.1111094,\n",
       "  'hedge-sd': 0.5443307,\n",
       "  'intensity-mean': 59.629630000000006,\n",
       "  'rawred-mean': 52.44444300000001,\n",
       "  'rawblue-mean': 75.22222,\n",
       "  'rawgreen-mean': 51.22222,\n",
       "  'exred-mean': -21.555555,\n",
       "  'exblue-mean': 46.77778,\n",
       "  'exgreen-mean': -25.222220999999998,\n",
       "  'value-mean': 75.22222,\n",
       "  'saturation-mean': 0.31899637,\n",
       "  'hue-mean': -2.0405545},\n",
       " 'path')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataset))\n",
    "(x,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Hoeffding Tree for Classification (HTC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We build the initial HTC model that does not (yet) see a data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.HoeffdingTreeClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the initial model is used for prediction, then an empty dictionary is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba_one(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The reason why the dictionary is empty, is because the model has not seen any data yet. \n",
    "* The data set is not yet known."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn_one(x, y)\n",
    "model.predict_proba_one(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Training\n",
    "\n",
    "* Training and Prediction on the first 50 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "path\n",
      "grass\n",
      "window\n",
      "foliage\n",
      "brickface\n",
      "grass\n",
      "grass\n",
      "grass\n",
      "brickface\n",
      "window\n",
      "window\n",
      "grass\n",
      "brickface\n",
      "grass\n",
      "grass\n",
      "window\n",
      "window\n",
      "brickface\n",
      "path\n",
      "window\n",
      "foliage\n",
      "cement\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for x, y in dataset:\n",
    "    y_pred = model.predict_one(x)\n",
    "    model.learn_one(x, y)\n",
    "    print(y_pred)\n",
    "    i = i +1\n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Information\n",
    "\n",
    "* Mehr: [river: Multi-class classification](https://riverml.xyz/0.13.0/introduction/getting-started/multiclass-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('spotCondaEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
