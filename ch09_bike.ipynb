{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Chapter 9\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the supplementary material of the books \"Online Machine Learning - Eine praxisorientiere Einführung\",  \n",
    "https://link.springer.com/book/9783658425043 and \"Online Machine Learning - A Practical Guide with Examples in Python\" https://link.springer.com/book/9789819970063\n",
    "The contents are open source and published under the \"BSD 3-Clause License\".\n",
    "This software is provided \"as is\" without warranty of any kind, either express or implied, including but not limited to implied warranties of merchantability and fitness for a particular purpose. The author or authors assume no liability for any damages or liability, whether in contract, tort, or otherwise, arising out of or in connection with the software or the use or other dealings with the software."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Bike Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as preprocessing_sklearn\n",
    "from sklearn import tree as sklearn_tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from spotRiver.evaluation.eval_bml import eval_bml_horizon, eval_bml_landmark, eval_bml_window, eval_oml_horizon, plot_bml_oml_horizon_predictions, plot_bml_oml_horizon_metrics\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from river import preprocessing as preprocessing_river\n",
    "from river import tree as river_tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "experiment_name = \"ch09_bike\"\n",
    "import os\n",
    "if not os.path.exists('./figures'):\n",
    "    os.makedirs('./figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-related feature engineering: \n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html presents an example that introduces different strategies to leverage time-related features for a bike sharing demand regression task that is highly dependent on business cycles (days, weeks, months) and yearly season cycles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bike Sharing Demand Dataset\n",
    "\n",
    "* To perform a data exploration on the Bike Sharing Demand dataset, the data is loaded from the OpenML repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "bike_sharing = fetch_openml(\n",
    "    \"Bike_Sharing_Demand\", version=2, as_frame=True, parser=\"pandas\"\n",
    ")\n",
    "df = bike_sharing.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[1:5].to_markdown(floatfmt=\".2f\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To get a quick understanding of the periodic patterns of the data, let's look at the average demand per hour during a week.\n",
    "* Note that the week starts on a Sunday, which is a weekend.\n",
    "* We can clearly distinguish between commuter traffic in the morning and evening of work days and recreational bicycle use on weekends, with peak demand in the middle of the days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "average_week_demand = df.groupby([\"weekday\", \"hour\"])[\"count\"].mean()\n",
    "average_week_demand.plot(ax=ax)\n",
    "_ = ax.set(\n",
    "    title=\"Average hourly bike demand during the week\",\n",
    "    xticks=[i * 24 for i in range(7)],\n",
    "    xticklabels=[\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"],\n",
    "    xlabel=\"Time of the week\",\n",
    "    ylabel=\"Number of bike rentals\",\n",
    ")\n",
    "plt.savefig(\"./figures/ch09_bike_demand_en.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "average_week_demand = df.groupby([\"weekday\", \"hour\"])[\"count\"].mean()\n",
    "average_week_demand.plot(ax=ax)\n",
    "_ = ax.set(\n",
    "    title=\"\",\n",
    "    xticks=[i * 24 for i in range(7)],\n",
    "    xticklabels=[\"So\", \"Mo\", \"Di\", \"Mi\", \"Do\", \"Fr\", \"Sa\"],\n",
    "    xlabel=\"Wochentag\",\n",
    "    ylabel=\"Anzahl verliehener Fahrräder\",\n",
    ")\n",
    "ax.grid(True)\n",
    "plt.savefig(\"./figures/ch09_bike_demand_de.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "average_week_demand = df.groupby([\"weekday\", \"hour\"])[\"count\"].mean()\n",
    "average_week_demand.plot(ax=ax)\n",
    "_ = ax.set(\n",
    "    title=\"\",\n",
    "    xticks=[i * 24 for i in range(7)],\n",
    "    xticklabels=[\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"],\n",
    "    xlabel=\"Weekday\",\n",
    "    ylabel=\"Number of Bike Rentals\",\n",
    ")\n",
    "ax.grid(True)\n",
    "plt.savefig(\"./figures/ch09_bike_demand.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The target of the prediction problem is the absolute count of bike rentals on a hourly basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The target variable (number of hourly bicycle rentals) is rescaled to predict relative demand so that the mean absolute error can be more easily interpreted as a fraction of the maximum demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"] = df[\"count\"] / df[\"count\"].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note:  \n",
    "    * The fitting method of the models used in this notebook minimizes the mean squared error to estimate the conditional mean, rather than the mean absolute error that would fit an estimator of the conditional median.\n",
    "    * When we report power measurement on the test set in the discussion, we focus instead on the mean absolute error, which is more intuitive than the root mean square error. \n",
    "* Note, however, that in this study the best models for one metric are also the best for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "df[\"count\"].hist(bins=30, ax=ax)\n",
    "_ = ax.set(\n",
    "    xlabel=\"Fraction of rented fleet demand\",\n",
    "    ylabel=\"Number of hours\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The input data frame is a timed hourly log of variables describing weather conditions. It contains both numeric and categorical variables.\n",
    "* Note that the time information has already been expanded into several supplemental columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"count\", axis=\"columns\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now introspect the distribution of the categorical variables, starting with \"weather\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weather\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since there are only 3 \"heavy_rain\" events, we cannot use this category to train machine learning models with cross validation.\n",
    "* Instead, we simplify the representation by collapsing those into the \"rain\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weather\"].replace(to_replace=\"heavy_rain\", value=\"rain\", inplace=True)\n",
    "df[\"weather\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the \"season\" variable is well balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"season\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.plot.stats import corrplot\n",
    "corrplot(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full, Train, and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_splits = list(ts_cv.split(X, y))\n",
    "# train_0, test_0 = all_splits[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into 60% for training and 40% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]\n",
    "k = int(n * 0.6)\n",
    "train = df[0:k]\n",
    "test = df[k:n]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Function `get_bike_sharing_data`\n",
    "\n",
    "The function `get_bike_sharing_data` from the `spotRiver` package is used to load the data from the OpenML repository. It implements the preprocessing steps described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.data.bike_sharing import get_bike_sharing_data\n",
    "df, train, test = get_bike_sharing_data()\n",
    "target_column=\"count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BML Linear regression\n",
    "\n",
    "* As usual for linear models, categorical variables need to be one-hot encoded.\n",
    "* For consistency, we scale the numerical features to the same 0-1 range using class:sklearn.preprocessing.MinMaxScaler, although in this case it does not impact the results much because they are already on comparable scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"weather\",\n",
    "    \"season\",\n",
    "    \"holiday\",\n",
    "    \"workingday\",\n",
    "]\n",
    "categories = [\n",
    "    [\"clear\", \"misty\", \"rain\"],\n",
    "    [\"spring\", \"summer\", \"fall\", \"winter\"],\n",
    "    [\"False\", \"True\"],\n",
    "    [\"False\", \"True\"],\n",
    "]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "alphas = np.logspace(-6, 6, 25)\n",
    "linear_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=MinMaxScaler(),\n",
    "    ),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizon set to one Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "metric = mean_absolute_error\n",
    "df_eval_bml_horizon_linear, df_true_bml_horizon_linear = eval_bml_horizon(model = linear_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, include_remainder=False, metric=metric)\n",
    "df_eval_bml_landmark_linear, df_true_bml_landmark_linear = eval_bml_landmark(model = linear_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_eval_bml_window_linear, df_true_bml_window_linear = eval_bml_window(model = linear_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The following figures are used in the book (fig-ch09_bike-overall-bml-lm-metrics and fig-ch09_bike-overall-bml-lm-predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = test.shape[0]\n",
    "a = int(m/2)-100\n",
    "b = int(m/2)\n",
    "df_labels=[\"linear_horizon\", \"linear_landmark\", \"linear_window\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_horizon_linear, df_eval_bml_landmark_linear, df_eval_bml_window_linear], df_labels=df_labels, cumulative=True, log_y=False, figsize=(10,5), metric=metric, filename=\"./figures/\" + experiment_name+\"_overall_bml_lm_metrics.pdf\")\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_horizon_linear[a:b], df_true_bml_landmark_linear[a:b], df_true_bml_window_linear[a:b]], target_column=target_column,  df_labels=df_labels, filename=\"./figures/\" + experiment_name+\"_overall_bml_lm_predictions.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## River OML: Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import evaluate\n",
    "from river import preprocessing\n",
    "from river import optim\n",
    "from river import feature_extraction\n",
    "from river import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_linear_model = compose.Select('humidity', 'temp', 'feel_temp', 'windspeed')\n",
    "oml_linear_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "oml_linear_model |= preprocessing.StandardScaler()\n",
    "oml_linear_model |= linear_model.LinearRegression()\n",
    "df_eval_oml_linear, df_true_oml_linear = eval_oml_horizon(model = oml_linear_model,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_labels=[\"oml_linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_oml_linear], log_y=False, df_labels=df_labels, metric=metric,filename=None)\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_oml_linear[a:b]], target_column=target_column,  df_labels=df_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labels=[\"bml_window_linear\", \"oml_linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_window_linear, df_eval_oml_linear], log_y=False, df_labels=df_labels, metric=metric)\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_window_linear[a:b], df_true_oml_linear[a:b]], target_column=target_column,  df_labels=df_labels, log_y=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Comparison of the BML and OML Linear Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The following figures are used in the book (fig-ch09_bike-overall-bml_oml_lm-metrics and fig-ch09_bike-overall-bml_oml_lm-predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"bml_horizon_linear\", \"bml_landmark_linear\", \"bml_window_linear\", \"oml_linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_horizon_linear, df_eval_bml_landmark_linear, df_eval_bml_window_linear, df_eval_oml_linear], df_labels=df_labels, cumulative=True, log_y=True, figsize=(10,5), metric=metric, filename=\"./figures/\" + experiment_name+\"_overall_bml_oml_lm_metrics.pdf\")\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_horizon_linear[a:b], df_true_bml_landmark_linear[a:b], df_true_bml_window_linear[a:b], df_true_oml_linear[a:b]], target_column=target_column,  df_labels=df_labels, filename=\"./figures/\" + experiment_name+\"_overall_bml_oml_lm_predictions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_linear_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also use the debug_one method to see what happens to one particular instance.\n",
    "* Let's train the model on the first 1,000 observations and then call debug_one on the next one.\n",
    "* To do this, we will turn the Bike object into a Python generator with iter() function.\n",
    "* The Pythonic way to read the first 1,000 elements of a generator is to use itertools.islice.\n",
    "* The debug_one method shows what happens to an input set of features, step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from river import stream, compose, feature_extraction, preprocessing, linear_model, stats\n",
    "import copy\n",
    "from spotRiver.data.bike_sharing import get_bike_sharing_data\n",
    "\n",
    "# oml_linear_model = compose.Select('humidity', 'temp', 'feel_temp', 'humidity', 'windspeed')\n",
    "oml_linear_model = compose.Select(\"year\", \"month\", \"hour\", \"weekday\", \"temp\", \"feel_temp\", \"humidity\", \"windspeed\")\n",
    "oml_linear_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "oml_linear_model |= preprocessing.StandardScaler()\n",
    "oml_linear_model |= linear_model.LinearRegression()\n",
    "\n",
    "_, train, test = get_bike_sharing_data()\n",
    "X = copy.deepcopy(test)\n",
    "y = X.pop(\"count\")\n",
    "dataset = stream.iter_pandas(X, y)\n",
    "\n",
    "for x, y in itertools.islice(dataset, 1000):\n",
    "    y_pred = oml_linear_model.predict_one(x)\n",
    "    oml_linear_model.learn_one(x, y)\n",
    "\n",
    "x, y = next(iter(dataset))\n",
    "print(oml_linear_model.debug_one(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic OML Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "from river import compose\n",
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "\n",
    "num = compose.SelectType(numbers.Number) | preprocessing.StandardScaler()\n",
    "cat = compose.SelectType(str) | preprocessing.OneHotEncoder()\n",
    "\n",
    "oml_linear_generic = compose.Pipeline((num + feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())),\n",
    "                                              linear_model.LinearRegression() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_oml_linear_generic, df_true_oml_linear_generic = eval_oml_horizon(model = oml_linear_generic,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_labels=[\"oml_linear\", \"oml_linear_generic\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_oml_linear, df_eval_oml_linear_generic], log_y=False, df_labels=df_labels, metric=metric)\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_oml_linear[a:b], df_true_oml_linear_generic[a:b]], target_column=target_column,  df_labels=df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oml_linear_generic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "* Gradient boosting regression with decision trees is often flexible enough to efficiently handle heteorogenic tabular data with a mixture of categorical and numerical features, as long as the number of samples is large enough.\n",
    "* Here, we perform minimal ordinal coding for the categorical variables and then let the model know to treat them as categorical variables using a special tree splitting rule.\n",
    "* Since we are using an ordinal encoder, we explicitly pass the list of categorical values to use a logical order in encoding the categories as integers instead of the lexicographic order.\n",
    "* This also has the added benefit of avoiding problems with unknown categories during cross-validation.\n",
    "* The numeric variables do not need to be preprocessed and for simplicity only the default hyperparameters are tried for this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "categorical_columns = [\n",
    "    \"weather\",\n",
    "    \"season\",\n",
    "    \"holiday\",\n",
    "    \"workingday\",\n",
    "]\n",
    "categories = [\n",
    "    [\"clear\", \"misty\", \"rain\"],\n",
    "    [\"spring\", \"summer\", \"fall\", \"winter\"],\n",
    "    [\"False\", \"True\"],\n",
    "    [\"False\", \"True\"],\n",
    "]\n",
    "ordinal_encoder = OrdinalEncoder(categories=categories)\n",
    "\n",
    "\n",
    "gbrt_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", ordinal_encoder, categorical_columns),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        # Use short feature names to make it easier to specify the categorical\n",
    "        # variables in the HistGradientBoostingRegressor in the next\n",
    "        # step of the pipeline.\n",
    "        verbose_feature_names_out=False,\n",
    "    ),\n",
    "    HistGradientBoostingRegressor(\n",
    "        categorical_features=categorical_columns,\n",
    "    ),\n",
    ").set_output(transform=\"pandas\")\n",
    "horizon = 7*24\n",
    "target_column = \"count\"\n",
    "df_eval_bml_horizon_gbrt, df_true_bml_horizon_gbrt = eval_bml_horizon(model = gbrt_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_eval_bml_landmark_gbrt, df_true_bml_landmark_gbrt = eval_bml_landmark(model = gbrt_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_eval_bml_window_gbrt, df_true_bml_window_gbrt = eval_bml_window(model = gbrt_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "df_labels=[\"gbrt_horizon\", \"gbrt_landmark\", \"gbrt_window\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_horizon_gbrt, df_eval_bml_landmark_gbrt, df_eval_bml_window_gbrt], df_labels=df_labels, cumulative=True, log_y=False, metric=metric)\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_horizon_gbrt[a:b], df_true_bml_landmark_gbrt[a:b], df_true_bml_window_gbrt[a:b]], target_column=target_column,  df_labels=df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: BML Gradient Boosting with OML Linear Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: These are the figures from the book (fig-ch09_bike-gbrt-olm-lm-metrics and fig-ch09_bike-gbrt-oml-lm-predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"gbrt_horizon\", \"gbrt_landmark\", \"gbrt_window\", \"oml_linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_bml_horizon_gbrt, df_eval_bml_landmark_gbrt, df_eval_bml_window_gbrt, df_eval_oml_linear], df_labels=df_labels, cumulative=True, log_y=False, figsize=(10,5), metric=metric, filename=\"./figures/\" + experiment_name+\"_gbrt_oml_metrics.pdf\")\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_horizon_gbrt[a:b], df_true_bml_landmark_gbrt[a:b], df_true_bml_window_gbrt[a:b], df_true_oml_linear[a:b]], target_column=target_column,  df_labels=df_labels, filename=\"./figures/\" + experiment_name+\"_gbrt_oml_predictions.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval_oml_iter_progressive \n",
    "\n",
    "* This experiment describes the evaluation of the OML Iterative Progressive Learning strategy. * A \"pure\" OML model is used, which does not use BML wrappers.\n",
    "* The prediction horizon is 1 hour, i.e., using progressive validation, each incoming example is used for prediction and then validation.\n",
    "* Validation is performed using the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotRiver.evaluation.eval_oml import eval_oml_iter_progressive, plot_oml_iter_progressive\n",
    "from spotRiver.data.bike_sharing import get_bike_sharing_data\n",
    "from river import metrics as river_metrics\n",
    "from river import stream as river_stream\n",
    "from river import preprocessing as river_preprocessing\n",
    "\n",
    "_, train, test = get_bike_sharing_data()\n",
    "X_test = copy.deepcopy(test)\n",
    "y_test = X_test.pop(\"count\")\n",
    "data_test = river_stream.iter_pandas(X_test, y_test)\n",
    "dataset_test = list(data_test)\n",
    "\n",
    "# oml_linear_model = compose.Select('humidity', 'temp', 'feel_temp', 'humidity', 'windspeed')\n",
    "oml_linear_model = compose.Select(\"year\", \"month\", \"hour\", \"weekday\", \"temp\", \"feel_temp\", \"humidity\", \"windspeed\")\n",
    "oml_linear_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "oml_linear_model |= preprocessing.StandardScaler()\n",
    "oml_linear_model |= linear_model.LinearRegression()\n",
    "\n",
    "res_num = eval_oml_iter_progressive(\n",
    "    dataset = list(dataset_test),\n",
    "    step = 1,\n",
    "    metric = river_metrics.MAE(),\n",
    "    models =\n",
    "    {\n",
    "        \"OML linear\": oml_linear_model,\n",
    "    }\n",
    ")\n",
    "plot_oml_iter_progressive(res_num, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_bml_horizon_1_gbrt, df_true_bml_horizon_1_gbrt = eval_bml_horizon(model = gbrt_pipeline,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=len(test), metric=metric)\n",
    "df_eval_bml_horizon_1_gbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = df[0:1]\n",
    "# test = df[1:-1]\n",
    "df_eval_4, df_true_4 = eval_oml_horizon(model = oml_linear_model,\n",
    "                            train = train.tail(10),\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=1,\n",
    "                            oml_grace_period=1,metric=metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"oml linear\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_4], log_y=True, df_labels=df_labels, cumulative=True, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"gbrt_horizon\", \"oml linear\"]\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_bml_horizon_gbrt[a:b], df_true_4[a:b]], target_column=target_column,  df_labels=df_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OML HTR/HATR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.tree import HoeffdingTreeRegressor, HoeffdingAdaptiveTreeRegressor\n",
    "from river import feature_extraction\n",
    "from river import stats, compose, preprocessing, tree\n",
    "\n",
    "#  The HTR Model\n",
    "\n",
    "htr_model = compose.Select(\"weekday\", \"month\", \"temp\", \"feel_temp\", \"humidity\", \"windspeed\")\n",
    "# compose.Select('humidity', 'temp', 'feel_temp', 'windspeed')\n",
    "htr_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "htr_model |= preprocessing.StandardScaler()\n",
    "# htr_model |= HoeffdingTreeRegressor()\n",
    "htr_model |= HoeffdingTreeRegressor(splitter=tree.splitter.QOSplitter())\n",
    "df_eval_htr, df_true_htr = eval_oml_horizon(model = htr_model,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)\n",
    "\n",
    "# The HATR Model\n",
    "\n",
    "hatr_model = compose.Select(\"weekday\", \"month\", \"temp\", \"feel_temp\", \"humidity\", \"windspeed\")\n",
    "# compose.Select('humidity', 'temp', 'feel_temp', 'windspeed')\n",
    "hatr_model += (\n",
    "    feature_extraction.TargetAgg(by=['hour'], how=stats.Mean())\n",
    ")\n",
    "hatr_model |= preprocessing.StandardScaler()\n",
    "hatr_model |= HoeffdingAdaptiveTreeRegressor(splitter=tree.splitter.QOSplitter())\n",
    "df_eval_hatr, df_true_hatr = eval_oml_horizon(model = hatr_model,\n",
    "                            train = train,\n",
    "                            test = test,\n",
    "                            target_column=target_column,\n",
    "                            horizon=horizon, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labels=[\"oml_linear\", \"htr\", \"hatr\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_oml_linear, df_eval_htr, df_eval_hatr], log_y=False, df_labels=df_labels, metric=metric, filename=\"./figures/\" + experiment_name+\"_oml_lm_htr_hatr_metrics.pdf\")\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_oml_linear[a:b], df_true_htr[a:b], df_true_hatr[a:b]], target_column=target_column,  df_labels=df_labels, filename=\"./figures/\" + experiment_name+\"_oml_lm_htr_hatr_predictions.pdf\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the  OML HTR/HATR Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"htr\", \"hatr\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_htr, df_eval_hatr], log_y=False, df_labels=df_labels, metric=metric)\n",
    "plot_bml_oml_horizon_predictions(df_true = [ df_true_htr[a:b], df_true_hatr[a:b]], target_column=target_column,  df_labels=df_labels, log_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=[\"oml_lm\", \"gbrt_horizon\", \"gbrt_landmark\", \"gbrt_window\", \"htr\"]\n",
    "plot_bml_oml_horizon_metrics(df_eval = [df_eval_oml_linear, df_eval_bml_horizon_gbrt, df_eval_bml_landmark_gbrt, df_eval_bml_window_gbrt, df_eval_htr], df_labels=df_labels, cumulative=True, log_y=False, log_x=False, figsize=(10,7), metric=metric, filename=\"./figures/\" + experiment_name+\"_overall_metrics.pdf\")\n",
    "plot_bml_oml_horizon_predictions(df_true = [df_true_oml_linear[a:b], df_true_bml_horizon_gbrt[a:b], df_true_bml_landmark_gbrt[a:b], df_true_bml_window_gbrt[a:b], df_true_htr[a:b]], target_column=target_column,  df_labels=df_labels, filename=\"./figures/\" + experiment_name+\"_overall_predictions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotCondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81c77de872def749acd68d9955e19f0df6803301f4c1f66c3444af66334112ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
